\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\thispagestyle {plain}}
\@writefile{toc}{\vspace {-.45cm}}
\citation{7}
\citation{15}
\citation{13}
\citation{24}
\citation{13}
\citation{3}
\citation{25}
\citation{13}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Eye Physiology}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Fixation}{1}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Saccades}{1}{subsection.2.2}}
\citation{1}
\citation{2}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Diagram of light and four Purkinje images.\relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{pimage}{{1}{2}{Diagram of light and four Purkinje images.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Eye Tracking and Gaze Estimation}{2}{section.3}}
\citation{3}
\citation{4}
\citation{13}
\citation{29}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}hEYEbrid: A Hybrid Approach for Mobile Calibration-free Gaze Estimation}{3}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Basic idea of hEYEbrid to use the pupil center in the corneal image (i.e. the environment reflected on the human eye) as the gaze point in the actual scene.\relax }}{3}{figure.caption.2}}
\newlabel{lander1}{{2}{3}{Basic idea of hEYEbrid to use the pupil center in the corneal image (i.e. the environment reflected on the human eye) as the gaze point in the actual scene.\relax }{figure.caption.2}{}}
\citation{15}
\citation{16}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Basic processing pipeline of hEYEbrid, which combines infrared eye and corneal images. The pupil is tracked in the IR image and mapped onto the corneal image to finally crop the reflection within the pupil. The mapped pupil center coincides with the gaze point.\relax }}{4}{figure.caption.3}}
\newlabel{lander2}{{3}{4}{Basic processing pipeline of hEYEbrid, which combines infrared eye and corneal images. The pupil is tracked in the IR image and mapped onto the corneal image to finally crop the reflection within the pupil. The mapped pupil center coincides with the gaze point.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Eye gaze tracking techniques for interactive applications}{4}{subsection.3.2}}
\newlabel{carlos1}{{4a}{5}{Dark\relax }{figure.caption.4}{}}
\newlabel{sub@carlos1}{{a}{5}{Dark\relax }{figure.caption.4}{}}
\newlabel{carlos2}{{4b}{5}{Bright\relax }{figure.caption.4}{}}
\newlabel{sub@carlos2}{{b}{5}{Bright\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Dark and bright pupil images.\relax }}{5}{figure.caption.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Purkinje images.\relax }}{5}{figure.caption.5}}
\newlabel{carlos3}{{5}{5}{Purkinje images.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}In the Eye of the Beholder: A Survey of Models for Eyes and Gaze}{5}{subsection.3.3}}
\citation{3}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The shape of the eye may change drastically when viewed from different angles. For example, the eyelids may appear straight from one view but highly curved from another. The iris contour also changes with viewing angle. The dashed lines indicate when the eyelids appear straight, while the solid yellow lines represent the major axis of the iris ellipse.\relax }}{6}{figure.caption.6}}
\newlabel{danwitzner}{{6}{6}{The shape of the eye may change drastically when viewed from different angles. For example, the eyelids may appear straight from one view but highly curved from another. The iris contour also changes with viewing angle. The dashed lines indicate when the eyelids appear straight, while the solid yellow lines represent the major axis of the iris ellipse.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces General model of the structures of the human eye, light, light sources, and projections.\relax }}{6}{figure.caption.7}}
\newlabel{danwitzner2}{{7}{6}{General model of the structures of the human eye, light, light sources, and projections.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Eye Tracking and Head Movement Detection: A State-of-Art Survey}{6}{subsection.3.4}}
\citation{9}
\citation{10}
\citation{10}
\citation{11}
\citation{12}
\citation{14}
\citation{20}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}I see what you see: Point of Gaze Estimation from Corneal Images}{8}{subsection.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Eye Gaze Tracking (EGT).\relax }}{8}{figure.caption.8}}
\newlabel{christian}{{8}{8}{Eye Gaze Tracking (EGT).\relax }{figure.caption.8}{}}
\citation{21}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Corneal Reflection Model.\relax }}{9}{figure.caption.9}}
\newlabel{christian}{{9}{9}{Corneal Reflection Model.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}A Probabilistic Approach to Online Eye Gaze Tracking Without Explicit Personal Calibration}{9}{subsection.3.6}}
\citation{22}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Probabilistic gaze estimation. (A) is the shown image. (B) is the saliency map $p(g|I)$ of the image. (C) is the gaze likelihood map given the optical axis. (D) is the gaze posterior probability map. The triangle shows the maximum posterior point. The circle shows the estimated gaze using the conventional method.\relax }}{10}{figure.caption.10}}
\newlabel{jixu}{{10}{10}{Probabilistic gaze estimation. (A) is the shown image. (B) is the saliency map $p(g|I)$ of the image. (C) is the gaze likelihood map given the optical axis. (D) is the gaze posterior probability map. The triangle shows the maximum posterior point. The circle shows the estimated gaze using the conventional method.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces An example of probabilistic gaze estimation result on three images. Red dots are the results of the proposed method. Blue dots are the results of the conventional method with 9-point calibration. The left column shows the gaze fixations superimposed on the original image, while the right column shows the fixations superimposed on the saliency map.\relax }}{11}{figure.caption.11}}
\newlabel{jix2}{{11}{11}{An example of probabilistic gaze estimation result on three images. Red dots are the results of the proposed method. Blue dots are the results of the conventional method with 9-point calibration. The left column shows the gaze fixations superimposed on the original image, while the right column shows the fixations superimposed on the saliency map.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Interacting with the Computer using Gaze Gestures}{11}{subsection.3.7}}
\citation{13}
\citation{26}
\citation{27}
\citation{4}
\citation{5}
\citation{6}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Video-based eye-tracking uses the reflection of an infrared LED and the center of the pupil to calculate the direction of the eye gaze. The reflection spot stays in the same position, while the pupil moves.\relax }}{12}{figure.caption.12}}
\newlabel{heiko}{{12}{12}{Video-based eye-tracking uses the reflection of an infrared LED and the center of the pupil to calculate the direction of the eye gaze. The reflection spot stays in the same position, while the pupil moves.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Calibration Strategies}{12}{section.4}}
\citation{4}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Pursuit calibration: making gaze calibration less tedious and more flexible}{13}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Pursuit calibration is based on moving targets (a), tolerates interruptions (b), can blend with application tasks (c) and calibrate users even when they are not aware (d).\relax }}{13}{figure.caption.13}}
\newlabel{kenpfeffer}{{13}{13}{Pursuit calibration is based on moving targets (a), tolerates interruptions (b), can blend with application tasks (c) and calibrate users even when they are not aware (d).\relax }{figure.caption.13}{}}
\citation{17}
\citation{18}
\citation{19}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}A Smooth Pursuit Calibration Technique}{14}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Orbits: Gaze Interaction for Smart Watches using Smooth Pursuit Eye Movements}{14}{subsection.4.3}}
\citation{19}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Top: a user raises the volume of his smart watch music player using Orbits gaze input controls. The UI shows the volume, pause/play and previous/next controls with orbiting targets for gaze selection. Bottom: how Orbits enables gaze input on smart watches. The technique can robustly detect which of the controls is actively being followed by correlating each Orbits\IeC {\textquoteright } target with the user\IeC {\textquoteright }s gaze.\relax }}{15}{figure.caption.14}}
\newlabel{augusto}{{14}{15}{Top: a user raises the volume of his smart watch music player using Orbits gaze input controls. The UI shows the volume, pause/play and previous/next controls with orbiting targets for gaze selection. Bottom: how Orbits enables gaze input on smart watches. The technique can robustly detect which of the controls is actively being followed by correlating each Orbits’ target with the user’s gaze.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Orbits: Enabling Gaze Interaction in Smart Watches Using Moving Targets}{15}{subsection.4.4}}
\citation{6}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Pursuits: Eye-based interaction with moving targets}{16}{subsection.4.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces When a user follows a moving object on the screen, her eyes perform the same trajectory as the followed object\IeC {\textquoteright }s.\relax }}{16}{figure.caption.15}}
\newlabel{melodie}{{15}{16}{When a user follows a moving object on the screen, her eyes perform the same trajectory as the followed object’s.\relax }{figure.caption.15}{}}
\citation{23}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces A user is interested in listening to a music album. She walks up to the in-store display, locates the album on the screen and follows its movement with her eyes. A sample of the music starts to play automatically.\relax }}{17}{figure.caption.16}}
\newlabel{melodie2}{{16}{17}{A user is interested in listening to a music album. She walks up to the in-store display, locates the album on the screen and follows its movement with her eyes. A sample of the music starts to play automatically.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Remote Point-of-gaze Estimation With Single-point Personal Calibration Based On The Pupil Boundary And Corneal Reflections}{17}{subsection.4.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Ray-tracing diagram (not to scale in order to be able to show all the elements of interest), showing schematic representations of an eye, a camera and a light source. Inset: eye image indicating the pupil and two corneal reflections.\relax }}{18}{figure.caption.17}}
\newlabel{elias}{{17}{18}{Ray-tracing diagram (not to scale in order to be able to show all the elements of interest), showing schematic representations of an eye, a camera and a light source. Inset: eye image indicating the pupil and two corneal reflections.\relax }{figure.caption.17}{}}
\citation{28}
\@writefile{toc}{\contentsline {section}{\numberline {5}Observations}{19}{section.5}}
\newlabel{obs1}{{18a}{19}{Reading\relax }{figure.caption.18}{}}
\newlabel{sub@obs1}{{a}{19}{Reading\relax }{figure.caption.18}{}}
\newlabel{obs2}{{18b}{19}{Watching media\relax }{figure.caption.18}{}}
\newlabel{sub@obs2}{{b}{19}{Watching media\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Sample saccade direction distributions for "reading" and "watching media" for participant 6.\relax }}{19}{figure.caption.18}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Sample scene images for each activity class annotated in the dataset showing the considerable variability in terms of place and time of recording. The red dot indicates the gaze location in that particular image.\relax }}{20}{figure.caption.19}}
\newlabel{obs3}{{19}{20}{Sample scene images for each activity class annotated in the dataset showing the considerable variability in terms of place and time of recording. The red dot indicates the gaze location in that particular image.\relax }{figure.caption.19}{}}
\bibcite{1}{1}
\bibcite{2}{2}
\bibcite{3}{3}
\bibcite{4}{4}
\bibcite{5}{5}
\bibcite{6}{6}
\bibcite{7}{7}
\bibcite{8}{8}
\bibcite{9}{9}
\bibcite{10}{10}
\bibcite{11}{11}
\bibcite{12}{12}
\bibcite{13}{13}
\bibcite{14}{14}
\bibcite{15}{15}
\bibcite{16}{16}
\bibcite{17}{17}
\bibcite{18}{18}
\bibcite{19}{19}
\bibcite{20}{20}
\bibcite{21}{21}
\bibcite{22}{22}
\bibcite{23}{23}
\bibcite{24}{24}
\bibcite{25}{25}
\bibcite{26}{26}
\bibcite{27}{27}
\bibcite{28}{28}
\bibcite{29}{29}
